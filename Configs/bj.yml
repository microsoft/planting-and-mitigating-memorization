# General parameters
mode: train
dataset_type: reddit
train_path: /home/t-adowney/reddit/reddit_tokenized_train.txt
dev_path: /home/t-adowney/reddit/reddit_tokenized_dev.txt
vocab_path: /home/t-adowney/reddit/vocab_20k.yml
canary_train_path: Canaries/canaries_tokenized.txt
canary_eval_path: Canaries/canaries_tokenized.txt
frequent_token_path: Canaries/start_words_512.txt
output_dir: Output/bj
seed: 1
print_every: 526
eval_every: 3682

# Model architecture
vocab_size: 20000
embedding_dim: 384
hidden_dim: 384
num_layers: 2
dropout: 0.1

# Training parameters
lr: 0.001
batch_size: 64
eval_batch_size: 128
num_epochs: 1
gradient_accumulation_steps: 1
patience: 16
schedule: linear
warmup_fraction: 0.0625
num_canary_insertions: 256
repeat_per_insertion: 16
random_suffix: true
truncate_train: 4194304
