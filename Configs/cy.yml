# General parameters
mode: train
dataset_type: reddit
train_path: /home/t-adowney/reddit/reddit_tokenized_train.txt
dev_path: /home/t-adowney/reddit/reddit_tokenized_dev.txt
vocab_path: /home/t-adowney/reddit/vocab_25k.yml
canary_train_path: Canaries/canaries_tokenized.txt
canary_eval_path: Canaries/canaries_tokenized.txt
frequent_token_path: Canaries/start_words_512.txt
output_dir: Output/cy
seed: 1
print_every: 526
eval_every: 3682

# Model architecture
vocab_size: 25000
embedding_dim: 512
hidden_dim: 512
num_layers: 2
dropout: 0.1

# Training parameters
lr: 0.001
l2_reg_term: 1.0e-06
batch_size: 64
eval_batch_size: 128
num_epochs: 1
gradient_accumulation_steps: 1
patience: 16
schedule: linear
warmup_fraction: 0.0625
num_canary_insertions: 32
repeat_per_insertion: 16
random_suffix: true
truncate_train: 4194304
